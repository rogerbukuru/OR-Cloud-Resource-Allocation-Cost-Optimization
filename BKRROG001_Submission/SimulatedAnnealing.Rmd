---
title: "SimulatedAnnealing"
author: "Roger Bukuru  (BKRROG001)"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(ggplot2)
library(dplyr)

rm(list = ls())

fileDir <- "vm_cloud_data.csv"
vm_cloud <- read.csv(fileDir)

vm_cloud <- vm_cloud[1:11000, -c(1,2)]

# One-hot encode character features
char_cols <- vm_cloud %>%
  select(where(is.character))

vm_cloud_encoded <- vm_cloud %>%
  mutate(across(where(is.character), as.factor)) %>%
  model.matrix(~ . - 1, data = .) %>%
  as.data.frame()

# Remove rows with null values
vm_cloud_clean <- vm_cloud_encoded %>%
  drop_na()

# Min-Max Normalize numeric features
min_max_normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

vm_cloud_standardized <- vm_cloud_clean %>%
  mutate(across(where(is.numeric), ~ min_max_normalize(.)))

head(vm_cloud_standardized, 10)


vm_cloud_clean_analysis <- vm_cloud_standardized %>%
  select(cpu_usage, memory_usage, network_traffic, power_consumption,
         num_executed_instructions, execution_time, energy_efficiency, task_priorityhigh, task_prioritylow, task_prioritymedium)

# Preview the cleaned data
head(vm_cloud_clean_analysis)

```


```{r}


objective_function <- function(solution, energy_efficiency, execution_time, 
                              cpu_usage, memory_usage, network_traffic, power_consumption, 
                              max_cpu, max_memory, max_net, max_pwr, penalty_weight) {
  # Calculate total execution time and energy efficiency
  total_execution_time <- sum(execution_time * solution)
  total_energy_efficiency <- sum(energy_efficiency * solution)
  
  # Calculate resource usage per server
  servers <- unique(solution)
  resource_overuse <- 0
  for (j in servers) {
    # Identify tasks assigned to server j
    tasks_j <- which(solution == j)
    
    # Sum resources used by these tasks
    total_cpu_j <- sum(cpu_usage[tasks_j])
    total_memory_j <- sum(memory_usage[tasks_j])
    total_net_j <- sum(network_traffic[tasks_j])
    total_pwr_j <- sum(power_consumption[tasks_j])
    
    # Calculate overuse for each resource
    over_cpu <- max(0, total_cpu_j - max_cpu)
    over_mem <- max(0, total_memory_j - max_memory)
    over_net <- max(0, total_net_j - max_net)
    over_pwr <- max(0, total_pwr_j - max_pwr)
    
    # Accumulate total overuse with penalties
    resource_overuse <- resource_overuse + (over_cpu + over_mem + over_net + over_pwr) * penalty_weight
  }
  
  # Total Objective
  # Minimize Execution Time and maximize Energy Efficiency
  # Implemented as: alpha * Execution_Time - beta * Energy_Efficiency + Penalties
  alpha <- 0.5  # Weight for Execution Time
  beta <- 0.5   # Weight for Energy Efficiency
  
  total_objective <- alpha * total_execution_time - beta * total_energy_efficiency + resource_overuse
  
  return(total_objective)
}

# Generate a random neighbor by reassigning a random task to a different server
generate_neighbor <- function(solution, num_servers) {
  neighbor <- solution
  task_to_change <- sample(1:length(solution), 1)
  current_server <- solution[task_to_change]
  # Assign to a different server
  possible_servers <- setdiff(1:num_servers, current_server)
  if (length(possible_servers) == 0) {
    # Only one server exists, no change
    return(neighbor)
  }
  new_server <- sample(possible_servers, 1)
  neighbor[task_to_change] <- new_server
  return(neighbor)
}

simulated_annealing <- function(initial_solution, energy_efficiency, execution_time, 
                                cpu_usage, memory_usage, network_traffic, power_consumption, 
                                max_cpu, max_memory, max_net, max_pwr, 
                                num_servers,
                                max_iter, init_temp, cooling_type, 
                                cooling_rate, alpha, 
                                penalty_weight) {
  # Initialize
  current_solution <- initial_solution
  best_solution <- current_solution
  current_temp <- init_temp
  best_objective <- objective_function(current_solution, energy_efficiency, execution_time, 
                                      cpu_usage, memory_usage, network_traffic, power_consumption, 
                                      max_cpu, max_memory, max_net, max_pwr, penalty_weight)
  
  # Store best objective value at each iteration
  objective_history <- numeric(max_iter)
  objective_history[1] <- best_objective
  
  for (i in 2:max_iter) {
    # Generate a neighbor solution
    neighbor <- generate_neighbor(current_solution, num_servers)
    
    # Calculate objective value for the neighbor
    neighbor_objective <- objective_function(neighbor, energy_efficiency, execution_time, 
                                             cpu_usage, memory_usage, network_traffic, power_consumption, 
                                             max_cpu, max_memory, max_net, max_pwr, penalty_weight)
    
    # Calculate the change in objective
    delta_objective <- neighbor_objective - best_objective
    
    # Accept the neighbor if it's better or based on acceptance probability
    if (delta_objective < 0 || runif(1) < exp(-delta_objective / current_temp)) {
      current_solution <- neighbor
      current_objective <- neighbor_objective
      
      # Update the best solution found so far
      if (current_objective < best_objective) {
        best_solution <- current_solution
        best_objective <- current_objective
      }
    }
    
    # Store the best objective so far
    objective_history[i] <- best_objective
    
    # --------------------------
    # Temperature cooldown
    # --------------------------
    
    if (cooling_type == "geometric") {
      # Geometric Cooling Rate: Temperature decreases by multiplying with a constant factor
      current_temp <- current_temp * (cooling_rate)^i
    } else if (cooling_type == "logarithmic") {
      # Logarithmic Cooling Rate: Temperature decreases based on the logarithm of the current iteration
      # Formula: T_k = T0 / (1 + alpha * log(1 + k))
      current_temp <- init_temp / (1 + alpha * log(1 + i))
    } else {
      stop("Invalid cooling_type. Choose either 'geometric' or 'logarithmic'.")
    }
    
    if (i %% 100 == 0) {
      cat("Iteration:", i, "Best Objective:", best_objective, "\n")
    }
  }
  
  return(list(best_solution = best_solution, best_objective = best_objective, 
              objective_history = objective_history))
}


```


```{r}

energy_efficiency <- vm_cloud_clean_analysis$energy_efficiency
execution_time <- vm_cloud_clean_analysis$execution_time
cpu_usage <- vm_cloud_clean_analysis$cpu_usage
memory_usage <- vm_cloud_clean_analysis$memory_usage
network_traffic <- vm_cloud_clean_analysis$network_traffic
power_consumption <- vm_cloud_clean_analysis$power_consumption

num_tasks <- length(energy_efficiency)
num_servers <- 35

# Server capacities
max_cpu <- 80
max_memory <- 80
max_net <- 80
max_pwr <- 80

# Initialize a feasible solution
# Simple heuristic: Assign each task randomly to a server
set.seed(123)  # For reproducibility
initial_solution <- sample(1:num_servers, num_tasks, replace = TRUE)

# SA Parameters
max_iter <- 100000
init_temp <- 50
cooling_rate <- 0.995
penalty_weight <- 10  # Penalty for resource overuse
alpha = 0.1

# Execute simulated annealing
result_sa <- simulated_annealing(initial_solution, energy_efficiency, execution_time, 
                                  cpu_usage, memory_usage, network_traffic, power_consumption, 
                                  max_cpu, max_memory, max_net, max_pwr, num_servers,
                                  max_iter, init_temp, cooling_type = "logarithmic", cooling_rate = cooling_rate, alpha = alpha,
                                  penalty_weight)

print(result_sa$best_solution)
print(paste("Best objective value:", result_sa$best_objective))


```


# Visualize Task Assignment Distribution

```{r}

objective_df <- data.frame(
  Iteration = 1:max_iter,
  Objective_Value = result_sa$objective_history
)

ggplot(objective_df, aes(x = Iteration, y = Objective_Value)) +
  geom_line(color = "blue") +
  labs(title = "Objective Function Convergence Over Iterations (Logarithmic Cooling)",
       x = "Iteration",
       y = "Objective Function Value") +
  theme_minimal()

```


```{r}

# Task assignments
assignments_sa <- data.frame(
  Task_ID = 1:num_tasks,
  Assigned_Server = result_sa$best_solution
)

head(assignments_sa)

# Aggregate the number of tasks per server
task_counts <- assignments_sa %>%
  group_by(Assigned_Server) %>%
  summarise(Num_Tasks = n())

task_counts <- task_counts %>%
  complete(Assigned_Server = 1:num_servers, fill = list(Num_Tasks = 0))


# Heatmap for Task Assignments
ggplot(task_counts, aes(x = factor(1), y = factor(Assigned_Server), fill = Num_Tasks)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Task Assignments Heatmap (Logarithmic Cooling)",
       x = "",
       y = "Server ID",
       fill = "Number of Tasks") +
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

# Aggregate the number of tasks per server
task_counts_sa <- assignments_sa %>%
  filter(!is.na(Assigned_Server)) %>%
  group_by(Assigned_Server) %>%
  summarise(Num_Tasks = n()) %>%
  complete(Assigned_Server = 1:num_servers, fill = list(Num_Tasks = 0))

# Bar plot for Task Distribution
ggplot(task_counts_sa, aes(x = factor(Assigned_Server), y = Num_Tasks)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Number of Tasks Assigned to Each Server (Logarithmic Cooling)",
       x = "Server ID",
       y = "Number of Tasks") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```