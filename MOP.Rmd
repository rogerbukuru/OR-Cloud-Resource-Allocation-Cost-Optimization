---
title: "MultiObjectiveGoalProgramming"
author: "Roger Bukuru"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load necessary libraries
library(tidyverse)
library(Rglpk)


# Clear workspace
rm(list = ls())

# Load data
fileDir <- "vm_cloud_data.csv"
vm_cloud <- read.csv(fileDir)

# Select relevant columns (skip the first two columns as mentioned)
vm_cloud <- vm_cloud[1:11000, -c(1,2)]

# Step 1: One-hot encode character features
# Identify character columns
char_cols <- vm_cloud %>%
  select(where(is.character))

# One-hot encode using pivot_wider
vm_cloud_encoded <- vm_cloud %>%
  mutate(across(where(is.character), as.factor)) %>%
  model.matrix(~ . - 1, data = .) %>%
  as.data.frame()

# Step 2: Remove rows with null values
vm_cloud_clean <- vm_cloud_encoded %>%
  drop_na()

# Step 3: Min-Max Normalize numeric features
min_max_normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# Apply min-max normalization to numeric columns
vm_cloud_standardized <- vm_cloud_clean %>%
  mutate(across(where(is.numeric), ~ min_max_normalize(.)))

# View the first few rows of the cleaned and normalized data
head(vm_cloud_standardized, 10)


# Select relevant columns for the optimization problem (after one-hot encoding and standardization)
vm_cloud_clean_analysis <- vm_cloud_standardized %>%
  select(cpu_usage, memory_usage, network_traffic, power_consumption,
         num_executed_instructions, execution_time, energy_efficiency, task_priorityhigh, task_prioritylow, task_prioritymedium)

# Preview the cleaned data
head(vm_cloud_clean_analysis)

#vm_cloud_clean_analysis = vm_cloud_clean_analysis[1:10,]

```

# Multi-Objective Goal Programming

## Archemedian 

```{r}
# Multi-Objective Goal Programming

## Archemedian 

# Archemedian Method Function using Rglpk for Task-to-Server Assignment
archemedian_goal_programming <- function(data, weights, max_cpu, max_memory, max_net, max_pwr) {
  
  # Number of tasks and servers
  num_tasks <- nrow(data)
  num_servers <- length(max_cpu)
  
  # Objective: Minimize weighted sum of energy efficiency and execution time
  obj_coeff <- rep(0, num_tasks * num_servers)
  
  for (j in 1:num_servers) {
    obj_coeff[((j - 1) * num_tasks + 1):(j * num_tasks)] <- weights["time"] * data$execution_time -weights["energy"] * data$energy_efficiency
                                                                 
  }
  
  # Constraints
  
  ## 1. Single Assignment Constraint
  constr_matrix_assign <- matrix(0, nrow = num_tasks, ncol = num_tasks * num_servers)
  
  for (i in 1:num_tasks) {
    for (j in 1:num_servers) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_assign[i, idx] <- 1
    }
  }
  
  constr_dir_assign <- rep("==", num_tasks)
  constr_rhs_assign <- rep(1, num_tasks)
  
  ## 2. CPU Constraints per Server
  constr_matrix_cpu <- matrix(0, nrow = num_servers, ncol = num_tasks * num_servers)
  
  for (j in 1:num_servers) {
    for (i in 1:num_tasks) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_cpu[j, idx] <- data$cpu_usage[i]
    }
  }
  
  constr_dir_cpu <- rep("<=", num_servers)
  constr_rhs_cpu <- max_cpu
  
  ## 3. Memory Constraints per Server
  constr_matrix_mem <- matrix(0, nrow = num_servers, ncol = num_tasks * num_servers)
  
  for (j in 1:num_servers) {
    for (i in 1:num_tasks) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_mem[j, idx] <- data$memory_usage[i]
    }
  }
  
  constr_dir_mem <- rep("<=", num_servers)
  constr_rhs_mem <- max_memory
  
  ## 4. Network Traffic Constraints per Server
  constr_matrix_net <- matrix(0, nrow = num_servers, ncol = num_tasks * num_servers)
  
  for (j in 1:num_servers) {
    for (i in 1:num_tasks) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_net[j, idx] <- data$network_traffic[i]
    }
  }
  
  constr_dir_net <- rep("<=", num_servers)
  constr_rhs_net <- max_net
  
  ## 5. Power Consumption Constraints per Server
  constr_matrix_pwr <- matrix(0, nrow = num_servers, ncol = num_tasks * num_servers)
  
  for (j in 1:num_servers) {
    for (i in 1:num_tasks) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_pwr[j, idx] <- data$power_consumption[i]
    }
  }
  
  constr_dir_pwr <- rep("<=", num_servers)
  constr_rhs_pwr <- max_pwr
  
  # Combine all constraints
  constr_matrix <- rbind(constr_matrix_assign, constr_matrix_cpu, constr_matrix_mem, constr_matrix_net, constr_matrix_pwr)
  constr_dir <- c(constr_dir_assign, constr_dir_cpu, constr_dir_mem, constr_dir_net, constr_dir_pwr)
  constr_rhs <- c(constr_rhs_assign, constr_rhs_cpu, constr_rhs_mem, constr_rhs_net, constr_rhs_pwr)
  
  # Variable types: Binary
  var_types <- rep("B", num_tasks * num_servers)
  
  # Solve the MIP using Rglpk
  solution <- Rglpk_solve_LP(
    obj = obj_coeff,
    mat = constr_matrix,
    dir = constr_dir,
    rhs = constr_rhs,
    types = var_types,
    max = FALSE  # Minimization
  )
  
  if (solution$status == 0) {  # 0 indicates success
    selected_tasks <- which(solution$solution == 1)
    assignments <- data.frame(
      Task_ID = rep(1:num_tasks, times = num_servers),
      Server_ID = rep(1:num_servers, each = num_tasks),
      Assigned = solution$solution == 1
    )
    assigned <- assignments %>% filter(Assigned == TRUE)
    
    # Calculate total objectives
    total_energy <- sum(data$energy_efficiency[assigned$Task_ID])
    total_time <- sum(data$execution_time[assigned$Task_ID])
    
    return(list(
      selected_tasks = assigned$Task_ID,
      server_assignments = assigned$Server_ID,
      total_energy = total_energy,
      total_time = total_time,
      objective_value = solution$objval
    ))
  } else {
    return(NULL)
  }
}

```

## Tchebycheff 

```{r}
## Tchebycheff 

# Tchebycheff Method Function using Rglpk for Task-to-Server Assignment
tchebycheff_goal_programming <- function(data, weights, max_cpu, max_memory, max_net, max_pwr) {
  
  # Number of tasks and servers
  num_tasks <- nrow(data)
  num_servers <- length(max_cpu)
  
  # Ideal values for objectives
  G1_ideal <- min(data$energy_efficiency)
  G2_ideal <- min(data$execution_time)
  
  # Number of decision variables: x_i_j for tasks and servers, plus Z
  num_variables <- num_tasks * num_servers + 1  # Last variable is Z
  
  # Objective: Minimize Z
  obj_coeff <- c(rep(0, num_tasks * num_servers), 1)
  
  # Constraints
  
  ## 1. Single Assignment Constraint
  constr_matrix_assign <- matrix(0, nrow = num_tasks, ncol = num_tasks * num_servers + 1)
  
  for (i in 1:num_tasks) {
    for (j in 1:num_servers) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_assign[i, idx] <- 1
    }
  }
  
  constr_dir_assign <- rep("==", num_tasks)
  constr_rhs_assign <- rep(1, num_tasks)
  
  ## 2. CPU Constraints per Server
  constr_matrix_cpu <- matrix(0, nrow = num_servers, ncol = num_tasks * num_servers + 1)
  
  for (j in 1:num_servers) {
    for (i in 1:num_tasks) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_cpu[j, idx] <- data$cpu_usage[i]
    }
  }
  
  constr_dir_cpu <- rep("<=", num_servers)
  constr_rhs_cpu <- max_cpu
  
  ## 3. Memory Constraints per Server
  constr_matrix_mem <- matrix(0, nrow = num_servers, ncol = num_tasks * num_servers + 1)
  
  for (j in 1:num_servers) {
    for (i in 1:num_tasks) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_mem[j, idx] <- data$memory_usage[i]
    }
  }
  
  constr_dir_mem <- rep("<=", num_servers)
  constr_rhs_mem <- max_memory
  
  ## 4. Network Traffic Constraints per Server
  constr_matrix_net <- matrix(0, nrow = num_servers, ncol = num_tasks * num_servers + 1)
  
  for (j in 1:num_servers) {
    for (i in 1:num_tasks) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_net[j, idx] <- data$network_traffic[i]
    }
  }
  
  constr_dir_net <- rep("<=", num_servers)
  constr_rhs_net <- max_net
  
  ## 5. Power Consumption Constraints per Server
  constr_matrix_pwr <- matrix(0, nrow = num_servers, ncol = num_tasks * num_servers + 1)
  
  for (j in 1:num_servers) {
    for (i in 1:num_tasks) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_pwr[j, idx] <- data$power_consumption[i]
    }
  }
  
  constr_dir_pwr <- rep("<=", num_servers)
  constr_rhs_pwr <- max_pwr
  
  ## 6. Tchebycheff Objective Constraints
  # For each objective, Z >= weight * (ideal - sum(objective * x_i_j))
  
  # Constraint for Energy Efficiency
  constr_matrix_tch_energy <- matrix(0, nrow = 1, ncol = num_tasks * num_servers + 1)
  for (j in 1:num_servers) {
    for (i in 1:num_tasks) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_tch_energy[1, idx] <- -weights["energy"] * data$energy_efficiency[i]
    }
  }
  constr_matrix_tch_energy[1, num_tasks * num_servers + 1] <- 1  # Coefficient for Z
  
  constr_dir_tch_energy <- ">="
  constr_rhs_tch_energy <- weights["energy"] * G1_ideal
  
  # Constraint for Execution Time
  constr_matrix_tch_time <- matrix(0, nrow = 1, ncol = num_tasks * num_servers + 1)
  for (j in 1:num_servers) {
    for (i in 1:num_tasks) {
      idx <- (j - 1) * num_tasks + i
      constr_matrix_tch_time[1, idx] <- -weights["time"] * data$execution_time[i]
    }
  }
  constr_matrix_tch_time[1, num_tasks * num_servers + 1] <- 1  # Coefficient for Z
  
  constr_dir_tch_time <- ">="
  constr_rhs_tch_time <- weights["time"] * G2_ideal
  
  # Combine Tchebycheff constraints
  constr_matrix_tch <- rbind(constr_matrix_tch_energy, constr_matrix_tch_time)
  
  constr_dir_tch <- c(constr_dir_tch_energy, constr_dir_tch_time)
  constr_rhs_tch <- c(constr_rhs_tch_energy, constr_rhs_tch_time)
  
  # Combine all constraints
  constr_matrix <- rbind(constr_matrix_assign, 
                         constr_matrix_cpu, 
                         constr_matrix_mem, 
                         constr_matrix_net, 
                         constr_matrix_pwr,
                         constr_matrix_tch)
  
  constr_dir <- c(constr_dir_assign, 
                 constr_dir_cpu, 
                 constr_dir_mem, 
                 constr_dir_net, 
                 constr_dir_pwr,
                 constr_dir_tch)
  
  constr_rhs <- c(constr_rhs_assign, 
                 constr_rhs_cpu, 
                 constr_rhs_mem, 
                 constr_rhs_net, 
                 constr_rhs_pwr,
                 constr_rhs_tch)
  
  # Variable types: Binary for x_i_j and Continuous for Z
  var_types <- c(rep("B", num_tasks * num_servers), "C")
  
  # Solve the MIP using Rglpk
  solution <- Rglpk_solve_LP(
    obj = obj_coeff,
    mat = constr_matrix,
    dir = constr_dir,
    rhs = constr_rhs,
    types = var_types,
    max = FALSE  # Minimization
  )
  
  if (solution$status == 0) {  # 0 indicates success
    # Extract assignments
    selected_tasks <- which(solution$solution[1:(num_tasks * num_servers)] == 1)
    assignments <- data.frame(
      Task_ID = rep(1:num_tasks, times = num_servers),
      Server_ID = rep(1:num_servers, each = num_tasks),
      Assigned = solution$solution[1:(num_tasks * num_servers)] == 1
    )
    assigned <- assignments %>% filter(Assigned == TRUE)
    
    # Extract Z value
    Z_value <- solution$solution[num_tasks * num_servers + 1]
    
    # Calculate total objectives
    total_energy <- sum(data$energy_efficiency[assigned$Task_ID])
    total_time <- sum(data$execution_time[assigned$Task_ID])
    
    return(list(
      selected_tasks = assigned$Task_ID,
      server_assignments = assigned$Server_ID,
      total_energy = total_energy,
      total_time = total_time,
      Z = Z_value
    ))
  } else {
    return(NULL)
  }
}


```



```{r}
# Define weights for the objectives
# Adjust weights based on the importance of each goal
weights <- c(energy = 0.5, time = 0.5)  # Equal importance

# Define resource constraints for each server
num_servers <- 35  # Number of servers
max_cpu <- rep(80, num_servers)        # Maximum CPU usage allowed per server
max_memory <- rep(80, num_servers)     # Maximum Memory usage allowed per server
max_net <- rep(80, num_servers)        # Maximum Network Traffic allowed per server
max_pwr <- rep(80, num_servers)        # Maximum Power Consumption allowed per server

# Apply Archemedian Goal Programming
archemedian_result <- archemedian_goal_programming(
  data = vm_cloud_clean_analysis,
  weights = weights,
  max_cpu = max_cpu,
  max_memory = max_memory,
  max_net = max_net,
  max_pwr = max_pwr
)

# Check if a solution was found using Archemedian Method
if (!is.null(archemedian_result)) {
  cat("Archemedian Method Solution:\n")
  cat("Selected Tasks:", archemedian_result$selected_tasks, "\n")
  cat("Server Assignments:", archemedian_result$server_assignments, "\n")
  cat("Total Energy Consumption:", archemedian_result$total_energy, "\n")
  cat("Total Execution Time:", archemedian_result$total_time, "\n")
  cat("Objective Value:", archemedian_result$objective_value, "\n\n")
} else {
  cat("No feasible solution found using the Archemedian Method.\n\n")
}


```


```{r}
# Apply Tchebycheff Goal Programming
tchebycheff_result <- tchebycheff_goal_programming(
  data = vm_cloud_clean_analysis,
  weights = weights,
  max_cpu = max_cpu,
  max_memory = max_memory,
  max_net = max_net,
  max_pwr = max_pwr
)

# Check if a solution was found using Tchebycheff Method
if (!is.null(tchebycheff_result)) {
  cat("Tchebycheff Method Solution:\n")
  cat("Selected Tasks:", tchebycheff_result$selected_tasks, "\n")
  cat("Server Assignments:", tchebycheff_result$server_assignments, "\n")
  cat("Total Energy Consumption:", tchebycheff_result$total_energy, "\n")
  cat("Total Execution Time:", tchebycheff_result$total_time, "\n")
  cat("Z (Maximum Weighted Deviation):", tchebycheff_result$Z, "\n")
} else {
  cat("No feasible solution found using the Tchebycheff Method.\n")
}


```


```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)

#save(task_counts, file="taskCount.Rdata")
#load("MOPWorkspace.Rdata")

# Function to prepare task distribution data
prepare_task_distribution <- function(result, method_name) {
  data.frame(
    Task_ID = result$selected_tasks,
    Server_ID = result$server_assignments,
    Method = method_name,
    Assigned = 1
  )
}

# Prepare data for both methods
task_dist_archemedian <- prepare_task_distribution(archemedian_result, "Archemedian")
task_dist_tchebycheff <- prepare_task_distribution(tchebycheff_result, "Tchebycheff")

# Combine data
task_distribution <- bind_rows(task_dist_archemedian, task_dist_tchebycheff)

# Aggregate number of tasks per server for each method
task_counts <- task_distribution %>%
  group_by(Method, Server_ID) %>%
  summarise(Num_Tasks = n()) %>%
  ungroup()

# Ensure all server-method combinations are represented
task_counts <- task_counts %>%
  complete(Method, Server_ID = 1:num_servers, fill = list(Num_Tasks = 0))


# Plot Task Distribution
ggplot(task_counts, aes(x = factor(Server_ID), y = Num_Tasks, fill = Method)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Task Distribution per Server",
       x = "Server ID",
       y = "Number of Tasks",
       fill = "Method") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  
# Save the plot
ggsave("task_distribution.png", width = 10, height = 6)


```


```{r}
prepare_task_distribution <- function(result, method_name) {
  data.frame(
    Task_ID = result$selected_tasks,
    Server_ID = result$server_assignments,
    Method = method_name,
    Assigned = 1  # Indicate assignment
  )
}


# Prepare data for both methods
task_dist_archemedian <- prepare_task_distribution(archemedian_result, "Archemedian")
task_dist_tchebycheff <- prepare_task_distribution(tchebycheff_result, "Tchebycheff")

# Combine data
task_distribution <- bind_rows(task_dist_archemedian, task_dist_tchebycheff)

# Create a complete grid of Servers and Tasks for both methods
servers <- 1:num_servers
tasks <- 1:nrow(vm_cloud_clean_analysis)  # Assuming one row per task

# Expand the grid to include all combinations
complete_grid <- expand.grid(
  Method = c("Archemedian", "Tchebycheff"),
  Server_ID = servers,
  Task_ID = tasks
)

# Merge with the actual assignments to create a binary indicator
heatmap_data <- complete_grid %>%
  left_join(task_distribution, by = c("Method", "Server_ID", "Task_ID")) %>%
  mutate(Assigned = ifelse(!is.na(Assigned), 1, 0))  # Now 'Assigned' exists



# Ensure that 'Method' is a factor for better plotting
heatmap_data$Method <- factor(heatmap_data$Method, levels = c("Archemedian", "Tchebycheff"))

# Function to generate heatmap for a given method
generate_heatmap <- function(data, method_name, output_file) {
  ggplot(data = data %>% filter(Method == method_name), 
         aes(x = factor(Task_ID), y = factor(Server_ID), fill = factor(Assigned))) +
    geom_tile(color = "white") +
    scale_fill_manual(values = c("0" = "white", "1" = "steelblue"),
                      labels = c("Not Assigned", "Assigned")) +
    labs(title = paste(method_name, "Method: Task Assignment Heatmap"),
         x = "Task ID",
         y = "Server ID",
         fill = "Assignment Status") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
          plot.title = element_text(hjust = 0.5))
  
  # Save the plot
  ggsave(output_file, width = 12, height = 8)
}

# Generate heatmaps for both methods
generate_heatmap(heatmap_data, "Archemedian", "heatmap_archemedian.png")
generate_heatmap(heatmap_data, "Tchebycheff", "heatmap_tchebycheff.png")


```




```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)

# Function to prepare task distribution data for a given method
prepare_task_distribution <- function(result, method_name) {
  data.frame(
    Task_ID = result$selected_tasks,
    Server_ID = result$server_assignments,
    Method = method_name,
    Assigned = 1  # Indicate assignment
  )
}

# Prepare data for both methods
task_dist_archemedian <- prepare_task_distribution(archemedian_result, "Archemedian")
task_dist_tchebycheff <- prepare_task_distribution(tchebycheff_result, "Tchebycheff")

# Combine data from both methods
task_distribution <- bind_rows(task_dist_archemedian, task_dist_tchebycheff)

# Aggregate the number of tasks per server for each method
task_counts_mop <- task_distribution %>%
  group_by(Method, Server_ID) %>%
  summarise(Num_Tasks = n()) %>%
  ungroup()

# Ensure all server-method combinations are represented
task_counts_mop <- task_counts_mop %>%
  complete(Method, Server_ID = 1:num_servers, fill = list(Num_Tasks = 0))

# Define servers and tasks
servers <- 1:num_servers
tasks <- 1:nrow(vm_cloud_clean_analysis)  # Assuming one row per task

# Create a complete grid of all combinations
complete_grid <- expand.grid(
  Method = c("Archemedian", "Tchebycheff"),
  Server_ID = servers,
  Task_ID = tasks
)

# Merge with actual assignments
heatmap_data <- complete_grid %>%
  left_join(task_distribution, by = c("Method", "Server_ID", "Task_ID")) %>%
  mutate(Assigned = ifelse(!is.na(Assigned), 1, 0))

heatmap_data$Method <- factor(heatmap_data$Method, levels = c("Archemedian", "Tchebycheff"))

# Function to generate heatmap for a given method
generate_heatmap_mop <- function(data, method_name, output_file) {
  # Aggregate number of tasks per server
  task_counts_mop_heatmap <- data %>%
    filter(Method == method_name) %>%
    group_by(Server_ID) %>%
    summarise(Num_Tasks = sum(Assigned)) %>%
    complete(Server_ID = 1:num_servers, fill = list(Num_Tasks = 0))
  
  # Plot Task Assignment Heatmap
  heatmap_plot <- ggplot(task_counts_mop_heatmap, aes(x = factor(1), y = factor(Server_ID), fill = Num_Tasks)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "lightblue", high = "darkblue") +
    labs(title = paste("Task Assignments Heatmap (MOP -", method_name, "Method)"),
         x = "",
         y = "Server ID",
         fill = "Number of Tasks") +
    theme_minimal() +
    theme(axis.text.x = element_blank(),
          axis.ticks.x = element_blank(),
          plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))
  
  # Display the heatmap
  print(heatmap_plot)
  
  # Save the heatmap to the images directory
  ggsave(output_file, plot = heatmap_plot, width = 12, height = 8)
}

# Generate heatmaps for both methods
generate_heatmap_mop(heatmap_data, "Archemedian", "images/heatmap_archemedian_mop.png")
generate_heatmap_mop(heatmap_data, "Tchebycheff", "images/heatmap_tchebycheff_mop.png")

# Bar Plot for Task Distribution for Both Methods
barplot_mop <- ggplot(task_counts_mop, aes(x = factor(Server_ID), y = Num_Tasks, fill = Method)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Number of Tasks Assigned to Each Server (MOP Methods)",
       x = "Server ID",
       y = "Number of Tasks",
       fill = "Method") +
  scale_fill_manual(values = c("Archemedian" = "steelblue", "Tchebycheff" = "darkorange")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        plot.title = element_text(hjust = 0.5, size = 14, face = "bold"))

# Display the bar plot
print(barplot_mop)

# Save the bar plot
ggsave("images/barplot_mop_methods.png", plot = barplot_mop, width = 12, height = 6)


```